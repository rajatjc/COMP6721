{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-18T05:52:18.538260873Z",
     "start_time": "2023-06-18T05:52:15.375385397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 01:52:16.178784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-18 01:52:16.351358: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-18 01:52:16.352344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-18 01:52:17.317846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy\n",
    "from pathlib import Path\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "IMG_SIZE_LOAD=64\n",
    "NUM_CLASSES = 5\n",
    "SEED = 77\n",
    "TRAIN_NUM = 1000 # use 1000 when you just want to explore new idea, use -1 for full train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T05:53:35.088568804Z",
     "start_time": "2023-06-18T05:53:34.664581159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dir = '/media/amanpreet/Windows-SSD/Users/siaya/Downloads/resized_train/resized_train/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T05:55:25.828881221Z",
     "start_time": "2023-06-18T05:55:25.782068815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      image  level\n0   10_left      0\n1  10_right      0\n2   13_left      0\n3  13_right      0\n4   15_left      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10_left</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10_right</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13_left</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13_right</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15_left</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_resize = '/media/amanpreet/Windows-SSD/Users/siaya/Downloads/trainLabels.csv'\n",
    "d_resize = pd.read_csv(p_resize)\n",
    "d_resize.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T05:55:52.029716195Z",
     "start_time": "2023-06-18T05:55:51.833816227Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def turn2DF(path):\n",
    "    dataframe_train = pd.read_csv(path)\n",
    "\n",
    "    for i in range(len(dataframe_train)):\n",
    "        dataframe_train=dataframe_train.replace(dataframe_train.loc[i,'image'], train_dir + str(dataframe_train.loc[i,'image']) + '.jpeg')\n",
    "\n",
    "    dataframe_train.to_csv('mydata.csv', index=False) # index=False để không lưu index của DataFrame vào file CSV"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T05:56:03.081257659Z",
     "start_time": "2023-06-18T05:56:03.050309102Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim == 2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "\n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img\n",
    "\n",
    "def load_ben_color(path, sigmaX=10):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (IMG_SIZE_LOAD, IMG_SIZE_LOAD))\n",
    "    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
    "\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T05:56:14.829975325Z",
     "start_time": "2023-06-18T05:56:14.823404842Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "def arr_img():\n",
    "    for i in range(len(d_resize)):\n",
    "        xdata = np.zeros((d_resize.shape[0], IMG_SIZE_LOAD, IMG_SIZE_LOAD, 3))\n",
    "        path = train_dir  + str(d_resize.loc[i,'image']) + '.jpeg'\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (IMG_SIZE_LOAD, IMG_SIZE_LOAD))\n",
    "        x = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        xdata[i] = x\n",
    "\n",
    "    xdata = xdata / 255.0\n",
    "    return xdata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T05:57:07.633140534Z",
     "start_time": "2023-06-18T05:57:07.627873419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = arr_img()\n",
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-18T05:57:10.857482386Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(d_resize['level'])\n",
    "y = to_categorical(y, num_classes = NUM_CLASSES)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 30, kernel_size = (5, 5), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 15, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Conv2D(filters = 15, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['categorical_accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
