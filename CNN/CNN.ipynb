{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T05:52:18.538260873Z",
     "start_time": "2023-06-18T05:52:15.375385397Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 01:52:16.178784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-18 01:52:16.351358: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-18 01:52:16.352344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-18 01:52:17.317846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T05:53:35.088568804Z",
     "start_time": "2023-06-18T05:53:34.664581159Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy\n",
    "from pathlib import Path\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the size of the loaded images\n",
    "IMG_SIZE_LOAD = 64\n",
    "\n",
    "# Define the number of classes\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "SEED = 77\n",
    "\n",
    "# Define the number of training samples to use\n",
    "TRAIN_NUM = 1000  # Use 1000 when you just want to explore a new idea, use -1 for full train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T05:55:25.828881221Z",
     "start_time": "2023-06-18T05:55:25.782068815Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dir = '/media/amanpreet/Windows-SSD/Users/siaya/Downloads/resized_train/resized_train/' #training directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T05:55:52.029716195Z",
     "start_time": "2023-06-18T05:55:51.833816227Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the file path of the CSV file\n",
    "p_resize = '/media/amanpreet/Windows-SSD/Users/siaya/Downloads/trainLabels.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "d_resize = pd.read_csv(p_resize)\n",
    "\n",
    "# Display the first five rows of the DataFrame\n",
    "d_resize.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T05:56:03.081257659Z",
     "start_time": "2023-06-18T05:56:03.050309102Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def turn2DF(path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    dataframe_train = pd.read_csv(path)\n",
    "\n",
    "    # Modify the values in the DataFrame\n",
    "    for i in range(len(dataframe_train)):\n",
    "        dataframe_train = dataframe_train.replace(dataframe_train.loc[i, 'image'], train_dir + str(dataframe_train.loc[i, 'image']) + '.jpeg')\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    dataframe_train.to_csv('mydata.csv', index=False)  # index=False to exclude the DataFrame's index from the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T05:56:14.829975325Z",
     "start_time": "2023-06-18T05:56:14.823404842Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def crop_image_from_gray(img, tol=7):\n",
    "    # Check if the input image is grayscale\n",
    "    if img.ndim == 2:\n",
    "        # Create a binary mask based on the tolerance value\n",
    "        mask = img > tol\n",
    "        # Apply the mask to the image to crop out dark regions\n",
    "        return img[np.ix_(mask.any(1), mask.any(0))]\n",
    "    elif img.ndim == 3:\n",
    "        # Convert the RGB image to grayscale\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # Create a binary mask based on the tolerance value\n",
    "        mask = gray_img > tol\n",
    "\n",
    "        # Check the shape of the resulting image after cropping\n",
    "        check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n",
    "        if check_shape == 0:\n",
    "            # If the resulting image is too dark and everything is cropped out,\n",
    "            # return the original image\n",
    "            return img\n",
    "        else:\n",
    "            # Crop each channel of the RGB image based on the mask\n",
    "            img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n",
    "\n",
    "            # Stack the cropped channels back together\n",
    "            img = np.stack([img1, img2, img3], axis=-1)\n",
    "        return img\n",
    "\n",
    "def load_ben_color(path, sigmaX=10):\n",
    "    # Load the image using OpenCV\n",
    "    image = cv2.imread(path)\n",
    "    # Convert the image to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Crop the image to remove dark regions\n",
    "    image = crop_image_from_gray(image)\n",
    "    # Resize the image to a specified size\n",
    "    image = cv2.resize(image, (IMG_SIZE_LOAD, IMG_SIZE_LOAD))\n",
    "    # Apply a weighted combination of the image and its Gaussian blur to enhance details\n",
    "    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), sigmaX), -4, 128)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T05:57:07.633140534Z",
     "start_time": "2023-06-18T05:57:07.627873419Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "def arr_img():\n",
    "    # Create an array to store the image data\n",
    "    xdata = np.zeros((d_resize.shape[0], IMG_SIZE_LOAD, IMG_SIZE_LOAD, 3))\n",
    "\n",
    "    # Iterate over the rows of the DataFrame\n",
    "    for i in range(len(d_resize)):\n",
    "        # Construct the path to the image\n",
    "        path = train_dir + str(d_resize.loc[i, 'image']) + '.jpeg'\n",
    "\n",
    "        # Read and resize the image using OpenCV\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.resize(image, (IMG_SIZE_LOAD, IMG_SIZE_LOAD))\n",
    "\n",
    "        # Convert the image to a NumPy array\n",
    "        x = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        # Store the image data in the array\n",
    "        xdata[i] = x\n",
    "\n",
    "    # Normalize the image data by dividing by 255.0\n",
    "    xdata = xdata / 255.0\n",
    "\n",
    "    return xdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-18T05:57:10.857482386Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "x_train = arr_img()\n",
    "\n",
    "# Check the shape of the processed image data\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "# Encode the labels in the 'level' column of the DataFrame\n",
    "y = lb.fit_transform(d_resize['level'])\n",
    "\n",
    "# Convert the encoded labels to one-hot encoded format\n",
    "y = to_categorical(y, num_classes=NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Conv2D layer with 30 filters, kernel size (5, 5), input shape (64, 64, 3), and ReLU activation\n",
    "model.add(Conv2D(filters=30, kernel_size=(5, 5), input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "# Add a MaxPooling2D layer with pool size (2, 2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a Dropout layer with a rate of 0.2\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add another Conv2D layer with 15 filters and kernel size (3, 3), followed by ReLU activation\n",
    "model.add(Conv2D(filters=15, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Add another Conv2D layer with 15 filters and kernel size (3, 3), followed by ReLU activation\n",
    "model.add(Conv2D(filters=15, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Add another MaxPooling2D layer with pool size (2, 2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add another Dropout layer with a rate of 0.2\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flatten the previous layer's output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a Dense layer with 128 units and ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add another Dense layer with 64 units and ReLU activation\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add another Dense layer with 32 units and ReLU activation\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the final Dense layer with 5 units for multi-class classification and softmax activation\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss, Adam optimizer, and metrics including categorical accuracy\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
